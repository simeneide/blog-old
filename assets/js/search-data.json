{
  
    
        "post0": {
            "title": "Running Google Colab with VS code",
            "content": "Running VScode and the python extension is great for development. I get clean python files and can run my code interactively. It is the same setup we have at work and I then remotely connect to a server with more cpu and GPU. However, for my side gigs I havent really figured out a workflow, until now. . This morning I found colab-ssh. It enables you to remotely connect your google colab instance to your local VScode! And if you have a GPU runtime on google colab you get that as well, of course. Combining this with a small google drive mounting, and I get more or less my local working environment but with GPU acceleration. . . A quick step-by-step (see colab-ssh for updates if this doesnt work): . Open a new google colab notebook. | In first cell: Mount your google drive using these commands (you need to follow link and authorize): from google.colab import drive drive.mount(&#39;/root/gdrive&#39;) . | Go to this site and get an ngrok token. | Second cell: Add your token and create a password. Then add+run this: | # Install colab_ssh on google colab !pip install colab_ssh --upgrade ngrokToken = &#39;XXX&#39; password = &#39;XXX&#39; from colab_ssh import launch_ssh, init_git launch_ssh(ngrokToken,password) . You‚Äôll now see something like this: | Collecting colab_ssh Downloading https://files.pythonhosted.org/packages/a7/c5/eedfd8b374fead9d863cb7031d9dc97fed50003372922ba0efd85d9fe3e0/colab_ssh-0.2.63-py3-none-any.whl Installing collected packages: colab-ssh Successfully installed colab-ssh-0.2.63 Successfully running 2.tcp.ngrok.io:13254 [Optional] You can also connect with VSCode SSH Remote extension using this configuration: Host google_colab_ssh HostName 2.tcp.ngrok.io User root Port 12345 . Go to your local VScode and select Remote-SSH: Open Configuration File, and paste the config above: | . . Select Remote-SSH: Connect to Host and select the google colab ssh connection. | . Voila! Up and running with gpu and your google drive attached. . Unfortunately, the hostname and port changes each time, and you still have to manually open the google colab. . Still, really great work by Wassim Benzarti. .",
            "url": "https://simeneide.github.io/blog/vscode/2020/09/14/colab-vscode-gpu.html",
            "relUrl": "/vscode/2020/09/14/colab-vscode-gpu.html",
            "date": " ‚Ä¢ Sep 14, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Installing Pytorch on a raspberry pi 4",
            "content": "Update 15 sept 2020 . I found these wheel builds from Thomas Viehmann that worked very well on a rpi4 64 bit running python 3.7. They are pytorch 1.6.0 and avoids the original hacks. Only issue was that my camera stopped working, but manage to circumvent it by using a different driver (v4l-utils) and using opencv‚Äôs VideoCapture() to get images. Got it running in a docker image with the following (removed some parts that I dont think is necessary): . (the balena docker image is a fairly stripped down ubuntu image) . FROM balenalib/raspberrypi4-64:latest # Defines our working directory in container WORKDIR /usr/src/app RUN sudo apt-get update RUN apt-get install -y gcc python3-dev v4l-utils python3-opencv python3-pip python3-setuptools libffi-dev libssl-dev # PYTORCH: RUN wget https://mathinf.com/pytorch/arm64/torch-1.6.0a0+b31f58d-cp37-cp37m-linux_aarch64.whl RUN wget https://mathinf.com/pytorch/arm64/torchvision-0.7.0a0+78ed10c-cp37-cp37m-linux_aarch64.whl RUN sudo apt-get install -y python3-numpy python3-wheel python3-setuptools python3-future python3-yaml python3-six python3-requests python3-pip python3-pillow RUN pip3 install torch*.whl torchvision*.whl . Original Post . Earlier this year I had to install pytorch on a raspiberry pi for my robotic lawn mower project (more on that later). However, the process was very painful, so Ill throw my notes here in case anyone else tries to do the same. Its not supposed to be bullet-proof, but may help with some pointers. Updates to this proceudre may be found here. . Installed from wheel on these: https://github.com/nmilosev/pytorch-arm-builds . But for rpi4 there was some errors, so I installed a wheel after reading this comment: https://github.com/nmilosev/pytorch-arm-builds/issues/4#issuecomment-527433112 . Install from his wheel a bit longer down the thread, and rename those _C..so and _d..so files to _C.so and _d.so. . Torchvision works, but Pillow 7.0.0 was too new, so downgraded to 6.1 after some random comments I found. . Step-by-step: . PIP install pytorch from wheel . Download wheel from here https://github.com/nmilosev/pytorch-arm-builds and run sudo pip3 install torch-1.1.0-cp37-cp37m-linux_armv7l.whl . Rename some files . Then if you try to run sudo python3 -c &quot;import torch&quot; you get: . Traceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/usr/local/lib/python3.7/dist-packages/torch/__init__.py&quot;, line 79, in &lt;module&gt; from torch._C import * ModuleNotFoundError: No module named &#39;torch._C&#39; . Can be fixed by the following: . cd /usr/local/lib/python3.7/dist-packages/torch sudo mv _C.cpython-37m-arm-linux-gnueabi.so _C.so sudo mv _dl.cpython-37m-arm-linux-gnueabi.so _dl.so .",
            "url": "https://simeneide.github.io/blog/rpi4/pytorch/2020/06/30/pytorch-raspberry.html",
            "relUrl": "/rpi4/pytorch/2020/06/30/pytorch-raspberry.html",
            "date": " ‚Ä¢ Jun 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "PILCO and Deep PILCO",
            "content": "Papers: . Deisenroth, M. P., &amp; Rasmussen, C. E. (2011). PILCO: A model-based and data-efficient approach to policy search. Proceedings of the 28th International Conference on Machine Learning, ICML 2011, 465‚Äì472. | Gal, Y., Mcallister, R. T., &amp; Rasmussen, C. E. (2016). Improving PILCO with Bayesian Neural Network Dynamics Models. Data-Efficient Machine Learning Workshop, ICML, 1‚Äì7. | . The papers shows how to find good policies with relatively few observations on classical control problems (mountain car, pole swing up etc) using probabilistic model based reinforcement learning. . Being model based in reinforcement learning means that you build a statistical model of the environment, a world model. The RL algorithm can then search for an optimal policy by simulating from this world model. This is more data efficient than in the ‚Äúmodel free‚Äù reinforcement learning algorithms, where one needs millions of examples to learn relatively simple games. However, model based simulators suffers from their approximations to the real world, which often ends up as huge errors when you simulate multiple steps. By introducing a probabilistic dynamics model, the PILCO algorithms tries to account for the fact that future trajectories are uncertain by introducing parameter uncertainty. The original PILCO paper does this by using Gaussian Processes, while the deep PILCO use a neural net with the ‚Äúdropout trick‚Äù to approximate a bayesian neural net. . . The framework assumes that the world model is of the form . $x_t=f(x_{t-1},u_{t-1})$ . where $x in R^d$ is a continuous state of the world at time t, $u_t in R^F$ is an action at time t, and f is some function of the real world transition dynamics. . The objective is to find a policy $ pi(x) = u$ that minimize the expectation of a cost function $c(x_t)$ over all time steps: . . The policy is found by iterating between learning the posterior of the world transition dynamics and simulating using the dynamics and optimizing the policy: . . The original paper uses a gaussian process to model $f(x_t)$, which gives an analytical solution for the posterior. However, gaussian processes does not scale well for large datasets, and the Deep PILCO paper instead uses a neural net to estimate the same dynamics. They approximate the posterior using variational inference and minimize the KL-divergence through using dropout, which can be interpreted as a variational bayesian approximation. . Both papers show that their algorithm is more data efficient than current state of the art reinforcement learning algorithms: . .",
            "url": "https://simeneide.github.io/blog/rl/2019/01/17/pilco+improve.html",
            "relUrl": "/rl/2019/01/17/pilco+improve.html",
            "date": " ‚Ä¢ Jan 17, 2019"
        }
        
    
  
    
        ,"post3": {
            "title": "BPMF presentation",
            "content": "Slides from my presentation on ‚ÄúBayesian Probabilistic Matrix Factorization using Markov Chain Monte Carlo‚Äù by Salakhutdinov and Mnih. Paper link. . .",
            "url": "https://simeneide.github.io/blog/bayesian/matrix%20factorization/mcmc/2018/10/06/bpmf-paper.html",
            "relUrl": "/bayesian/matrix%20factorization/mcmc/2018/10/06/bpmf-paper.html",
            "date": " ‚Ä¢ Oct 6, 2018"
        }
        
    
  
    
        ,"post4": {
            "title": "Takeaways Recsys 2018",
            "content": "For the first time Ive actually made a summary of all the papers and presentations I found noteworthy at a conference (allright, there were more, but this is a start). Below is my notes, with links etc. The purpose of the notes is mainly for myself to remember and revisit what I found interesting, but I see no reasons not to share to others. Does not include my own paper. . Keynote dlrs - Joachims: Deep learning with logged bandit feedback . Paper: http://www.cs.cornell.edu/people/tj/publications/joachims_etal_18a.pdf | idea: utilize current policy to build a better contextual bandits to recommend. | using Inverse Propensity Scoring | Using Self-normalizing IPS estimator (SNIPS) | Also using self normalizing | . . . . A very similar talk seem to be posted here: . Youtube, Minmin Chen: Off-policy correction for a REINFORCE Rec system . Invited talk on the evaluation workshop REVEAL | Youtube shared their work on how the models they used now works, focus on evaluation | Maximized recommendations based on expected future reward | they do not use td to train the model, rather the all the actual future rewards and discounts them to get training signal. | . . . Corrects off-policy updates with importance sampling/IPS . | Exploration is costly, so they tune ut with an extra weight that they set. | Recommends a set of top K items. Assume additive rewards: | . . Results . Improved recs, also able to recommend more items into the tail. | . . Recsys-competition winners: Two-stage model for Automatic Playlist Continuation at Scale . Challenge website: http://www.recsyschallenge.com/2018/ | Winner paper: http://www.cs.toronto.edu/~mvolkovs/recsys2018_challenge.pdf | Task was to complete a user playlist at spotify. | A playlist may have be created over a long time. | Given the first items, predict the last ones. | . Approach: . step 1: Reduce candidate set of all items to 20k by using a temporal convolutional layer. (lstm worked too, but was slower to train and iterate on). | The step 1 was really about maximizing recall. | . | Step 2: xgboost classifier on these candidates | . . Categorical-attributes-based item classification for recommender systems: hiarchical softmax and multi loss . Paper: https://dl.acm.org/citation.cfm?id=3240367 | Setting: Next item prediction with items within some category structure. | Using negative sampling during training . | Does the recommender improve by predicting a hiarchical softmax instead of doing multi target prediction? . | Result: Using hiarchical modeling is better than multi target. Testet with MAP@5 on recsys16 dataset and ‚Äúlarge propertary dataset‚Äù. | Also helps with cold start | . Own comments: Unsure of the improvement is due to negative sampling or that you infer more structure in your data/model. . &quot;Categorical-Attributes-Based Item Classification for Recommender Systems&quot; by @QianZhao3 and Google folks lead by @edchi - really interesting idea: categorical labels as *outputs* of multitask model you are optimizing when recommending items #RecSys2018 https://t.co/Bkljw0zVFf pic.twitter.com/PavBxdtLaX . &mdash; Xavier @ #recsys2018üéóü§ñüèÉ (@xamat) October 5, 2018 . . Keynote 2 dlrs - Ray Jiang, deepmind: slate recommendation (part 1) . Relevant paper (seems unpublished): https://arxiv.org/pdf/1803.01682.pdf | predict a full feed instead of single items | use a VAE to do this, | ‚ÄúWorks really well‚Äù. | Tested on Recsys 2015: was the best slate dataset they could find | . . . https://arxiv.org/abs/1803.01682 . Calibrated Recommendations . Paper: https://dl.acm.org/citation.cfm?id=3240372 | If you have seen 70% drama and 30% horror, optimizing a recommender on precision, the best solution is to give you 100% drama and get 70% precision. | The paper suggests to calibrate the recommendations to be more representative. | Done by regularizing the recommendations with the KL divergence of categories (genres in this case) | Done as a post processing step. | Result: Can rerank top recommendations to a much more representative distribution without losing accuracy. | . https://dl.acm.org/citation.cfm?id=3240372 . Explore, Exploit, and Explain: Personalizing Explainable Recommendations with Bandits . Paper: https://dl.acm.org/citation.cfm?id=3240354 | Feed-bandit that uses a factorization machine to predict and explain recommendations | context: Home page of spotify account. Different shelves of recommendations, each with an explanation (‚Äúbecause you recently listened to..‚Äù) | . Invited talk Netflix: Correlation &amp; Causation . Yves Raimond, AI director Netflix | Netflix‚Äôs approach: personalize everything | Made some thoughts about the do operator P(Y | do(X)) | . | Maybe better for recs to focus on P(click | do(X)) - P(click | not do X) | . | IPS: | pro: simple, model-agnostic | con: only unbiased if no unobserved cofounders, high variance | Alternative til IPS: Instrumental Variable | used in econometrics | pro: robust to unobserved cofounders | con: bias/var depends on strength of IV, hard to scale | . . . Generation meets recommendation - ‚ÄúGenerating new items that fit most users‚Äù . Paper: https://arxiv.org/abs/1808.01199 | . ‚ÄúConsider a movie studio aiming to produce a set of new movies for summer release: What types of movies it should produce? Who would the movies appeal to?‚Äù | ‚ÄúSpecifically, we leverage the latent space obtained by training a deep generative model‚Äîthe Variational Autoencoder (VAE)‚Äîvia a loss function that incorporates both rating performance and item reconstruction terms.‚Äù | ‚ÄúWe then apply a greedy search algorithm that utilizes this learned latent space to jointly obtain K plausible new items, and user groups that would find the items appealing.‚Äù | . On the robustness and discriminative power of information retrieval metrics for top-N recommendation . Paper: https://dl.acm.org/authorize.cfm?key=N668684 | An evaluation of robustness of many offline metrics at different ranking level. E.g. MRR@5, Recall@10, MAP@100, ‚Ä¶ . | Takeaway 1: Use a high cutoff (e.g. 100 instead of 10) when doing offline evaluations, like MRR. The metric is more robust, and highly correlated to the MRR@10 values | Takeaway 2: MRR is one of the lesser robust offline metrics. | . . Takeaway 2: mrr er ganske lite robust. . Unbiased offline recommender evaluation for missing-not-at-random implicit feedback . Implicit-feedback Recommenders (ImplicitRec) leverage positive only user-item interactions, such as clicks, to learn personalized user preferences. Recommenders are often evaluated and compared offline using datasets collected from online platforms. These platforms are subject to popularity bias (i.e., popular items are more likely to be presented and interacted with), and therefore logged ground truth data are Missing-Not-At-Random (MNAR). . ‚ÄúAverage over all‚Äù estimators are biased in Implicit rec datasets | Use IPS to evaluate policies. | reduce bias with 30% in a yahoo! music datset. | Paper: https://dl.acm.org/citation.cfm?id=3240355 | . RecoGym . Simulation environment where you can evaluate your recommender agent | Follows the same style as openAI gym: env.step(action) | When we tried it a bit the day before, the users seemed to click on the same items over and over again, probably some tuning that needs to be done there? | This is sort of an alternative approach to offline evaluation. Simulators are limited by their generating model, but can we still use it to test algorithms for convergence etc? . | Unrelated to talk and recogym, but some notes me and Olav did on rec simulations during conf. Same ideas: | . . News session-based recommendations using DNN . A recommendation algorithm to recommend news. | Freshness and coldstart big problems. | Separate item representation that uses a lot of content, independent of users | Unfortunately not tested in prod (authors from large news corp.) | Tested on offline data: Beats everything, incl gru4rec ++ | Paper: https://arxiv.org/abs/1808.00720 | Code: https://github.com/criteo-research/reco-gym | . . What happens if users only share last n days of data? (Exploring recommendations under user-controlled data filtering) . ‚ÄúUsing the MovieLens dataset as a testbed, we evaluated three widely used collaborative filtering algorithms.‚Äù | ‚ÄúOur experiments demonstrate that filtering out historical user data does not significantly affect the overall recommendation performance.‚Äù | Impacts those who opted out (naturally) | . Paper: https://scholar.google.com/citations?user=Vyj2jeoAAAAJ&amp;hl=en#d=gs_md_cita-d&amp;p=&amp;u=%2Fcitations%3Fview_op%3Dview_citation%26hl%3Den%26user%3DVyj2jeoAAAAJ%26citation_for_view%3DVyj2jeoAAAAJ%3A2osOgNQ5qMEC%26tzom%3D420 . Interactive recommendation via deep neural memory augmented contextual bandits . created a recsys simulator? check out‚Ä¶ | Paper: https://dl.acm.org/citation.cfm?id=3240344 | .",
            "url": "https://simeneide.github.io/blog/recsys/conference/2018/10/06/recsys2018.html",
            "relUrl": "/recsys/conference/2018/10/06/recsys2018.html",
            "date": " ‚Ä¢ Oct 6, 2018"
        }
        
    
  
    
        ,"post5": {
            "title": "KDD workshop Deep learning Day: Five lessons from building a deep neural network recommender for marketplaces",
            "content": "Ning Zhou, Audun √òygard and I got a paper in the KDD workshop Deep Learning Day. We provide some practitioner‚Äôs findings on applying deep learning recommendations in production! Link to paper here. . Together with @nzhou9 and @matsiyatzy, I am officially moving into academia after being an industrial observer: We got a paper in the #KDD2018 workshop Deep Learning Day. We provide some practitioner&#39;s findings on applying deep learning recommendations in production! . &mdash; Simen Eide (@simeneide) August 18, 2018 That was fun. pic.twitter.com/KBLjYlvzS9 . &mdash; Simen Eide (@simeneide) August 20, 2018 Poster: .",
            "url": "https://simeneide.github.io/blog/conference/2018/08/19/kdd-workshop.html",
            "relUrl": "/conference/2018/08/19/kdd-workshop.html",
            "date": " ‚Ä¢ Aug 19, 2018"
        }
        
    
  
    
        ,"post6": {
            "title": "Deep Recommenders, Car Pricing, Self driving rc-car and other projects in 2017",
            "content": "I am not a fan of new years resolutions. If I had been, one of my new years resolutions would be to be better at writing down what I am doing all the time. However, I held some talks and did some fun experiments in 2017, so the cheap way is simply to link to those. . How to become a Data Scientist in 20 minutes (JavaZone 2017) . At Javazone 2017 I held a short talk on how building (drum roll) machine learning algorithms is actually pretty easy. Simply put: I build a regression model that would predict the fair price of a car, and then I explained how I used that model to actually buy the car. The main message was that as long as you do your model validation properly (dont train and test on same data), you dont really need to understand the algorithm to get good results (use random forest!). . We published both algorithm and the dataset here so that anyone could replicate it, and JavaZone even filmed it: . Algorithms we are using in FINN.no to recommend you good stuff . . I have actually held three talks on this. First off was the one I held at Oslo Data Science meetup in February, where I talked about the journey we did from pure CF-models to using Tensorflow. . After that we have tried out a lot of things, and also moved to use keras instead, so we could skip all the boilerplate. Ive held two talks this fall on it: one beer-talk hosted by Bekk Consulting, and one early-morning talk with Bearpoint. The presentations were very similar, and can be downloaded here. . Testing RNN #recommenders for @FINN_tech. The RNN (bottom) generalize better when looking at last 10 items compared to only the last (mid). pic.twitter.com/feZMcz1n97 . &mdash; Simen Eide (@simeneide) August 31, 2017 Workshop for FINN developers on Machine Learning . In November I held a 3 hour workshop with some colleages on machine learning. The idea was, just as in the javazone talk, to demystify building these models. We spun up GPU machines to all the participants, prepared a dataset many FINN ads and a baseline script on how they could classify the ads based on their title. It was around 500‚Äô000 ads spread over 20 or so categories. The task was then to understand the baseline algorithm, then improve it by changing architechture, learning rates, optimizers and so on. The baseline started by taking averages of the word2vec vectors of the title, but the winners used a GRU-layer on the title to snitch the last percentage points on the validation accuracy. That was really impressive, none of them had done machine learning before, and then they start tinkering with recurrent neural nets! . Data scientist beware! Sixty developers at @FINN_tech with no prior #MachineLearning experience just build a deep neural classifier in 2.5hrs that beat my model! pic.twitter.com/HmG29pi7mM . &mdash; Simen Eide (@simeneide) November 21, 2017 Clothing GANs . We had a little GAN-workshop at the end of the year here, where we among other things trained a model to generate new clothing. I was impressed how easy that was. Maybe FINN should start generating images of your ad if you cant be bothered to take your own photos? ;) . Do you need to sell off some clothes at @FINN_tech, but not happy with your own image? This is our first try at building a #GAN model that can generate arbitrary clothing images for you! Next steps: upscaling, conditioning and maybe a fashion show? pic.twitter.com/Vkd7takdHT . &mdash; Simen Eide (@simeneide) December 17, 2017 Neural Search Engines . Ive tried to work on models that take text input and outputs a finn ad (aka search engine). They were also enhanced with user-features, so that the search would be personalized to the exact user. It worked all right, but we are currently working on a ‚Äúsimpler‚Äù way to personalize FINNs search results, combining the good old search engine with our recommendation models. . Search engines are maybe not the most sexy, but it was really fun to learn a model to predict our #recommendation vectors based on a word! pic.twitter.com/yPDsLkKYxc . &mdash; Simen Eide (@simeneide) September 5, 2017 Self driving rc-car ++ . Ive been tinkering a bit with a self driving car. The project is called donkeycar. Basically it is a rc-car that you can run through a python API with a raspberry pi. They have also integrated tensorflow, so that you can use imitation learning to drive a path. I got it to follow the road, and also a white line. Hopes was to spend enough time to build some reinforcement learning into it, but I haven‚Äôt had time (yet!). . Bil + nevralt nett = SELVKJ√òRENDE BIL! Kan jeg claime Norges f√∏rste selvkj√∏rende amat√∏rbil?! #autonomousdriving #donkeycar #in #DeepLearning pic.twitter.com/vwZJcfLqLd . &mdash; Simen Eide (@simeneide) August 18, 2017 Our self driving project isnt fast, but atleast can go on forever. Driving using a single neural network on a raspberry PI #donkeycar pic.twitter.com/6y5sf8AnMi . &mdash; Simen Eide (@simeneide) October 28, 2017 How my #donkeycar is detecting road, grass and horizon for #autonomousdriving. Slow and steady progress.. pic.twitter.com/VlL3hGmcWn . &mdash; Simen Eide (@simeneide) September 1, 2017",
            "url": "https://simeneide.github.io/blog/recsys/carprice/autonomous%20cars/2018/01/03/talks-and-projects-2017.html",
            "relUrl": "/recsys/carprice/autonomous%20cars/2018/01/03/talks-and-projects-2017.html",
            "date": " ‚Ä¢ Jan 3, 2018"
        }
        
    
  
    
        ,"post7": {
            "title": "Deep NLP-based Recommenders at Finn.no",
            "content": "During a hackathon at FINN.no, we figured we wanted to learn more about deep NLP-models. FINN.no has a large database with ads of people trying to sell stuff (around 1 million active ads at any time), and they are categorized into a category tree with three or four layers. For example, full suspension bikes can be found under ‚ÄúSport and outdoor activities‚Äù / ‚ÄúBike sport‚Äù / ‚ÄúFull suspension bikes‚Äù. . In our daily jobs we are working on recommendations. There, we already have a content based (tf-idf) recommender build on Solr‚Äôs More Like This. It seems to work well in areas where our collaborative filtering approaches does not. Would it be possible to build a deep learning NLP-model of similar performance? . To achieve a measure of similarity, building a classifier of the previously mentioned categories seemed like a good choice, since we already had a lot of pre-existing data. The NLP team at Schibsted had already tokenized around six million ads as well as trained a word2vec model for us - we were ready to roll! . Some preprocessing still had to be done. We ran through all ads, concatenated the title and description strings, and after a quick look at the data took the first 15 words of each ad. . Model architecture proposed by the paper Our initial experiments were done with a simple ‚ÄúBag of words‚Äù model included in the Keras repository, but we promptly switched over to ‚ÄúConvolutional Neural Networks for Sentence Classification‚Äù based architecture after hearing about it from our colleague, Tobias. By looking at the first 15 words of the ad, and using 200 dimensional embeddings for each word, our input is transformed into a 15x200 matrix. We apply three different convolutions on each document. The three convolutions looks at 2, 3 and 4 words (kernel sizes) in each convolution. It then max-pools each over the whole document, so that you end up with one value per document per convolution. For each kernel size you do 100 different filters. Finally you add a dense layer for classification. In addition to the standard model described in the paper, we experimented with different kernel sizes, number of filters, dense layers, batch normalization and dropout. We also added several losses, so that the model optimized both the higher and lower category at the same time. That helped. . Keras representation of our NLP model So how did it go? Our hackathon model managed to categorize 10‚Äô000 ads into 359 categories with an accuracy of 50%. We were surprised it worked so well, it was about the same accuracy image models have achieved on roughly the same ads. After tuning and pruning it further and adding 1 million data points, we have reached an accuracy of 70% on the 359 classes. In comparison, the bag-of-words model we started with managed an accuracy rate of around 25% and image recognition models have reached accuracies around 50%. . Using the model in recommendations . It is usually the case that category-similarity translates decently to ad-similarity. Using our classifier model we can serve users more ads similar to what they‚Äôre already seeing, based on the text of a selected ad. . We use the model by cutting the last dense layer (called feature layer in figure above), then comparing normalized dot products (cosine similarity) between objects. Since our our benchmarks for judging anything a success or failure is based on how it performs in a production environment, we went ahead and did that. This gave us decent results using only text, performing about 5-6% percent worse than our top collaborative filtering approach. When we made an ensemble model combining text and collaborative filtering we managed to improve our existing best model by about 10%. This is likely due to better supporting ‚Äúcold ads‚Äù, or ads without traffic, while still retaining the accuracy of the collaborative filtering-model. . An example of a ‚Äúcold ad‚Äù, where we think our NLP model does a better job at finding relevancy than the traditional collaborative filtering approach Collaborative filtering recommendations NLP Recommendations Further work . The pure text-model does not prioritize the popularity (or perhaps by proxy, how good the ad is) of the ad at all. This leads us to suspect that although users are being directed to similar ads, they could for example be missing an enticing image to make engagement likely. Seeing how the ensemble model in the end is optimized for click-rate, it likely only gives the NLP model high priority when the ad has low traffic. It would be interesting to somehow introduce this aspect into the NLP model. . We would like to eventually have a more thorough NLP representation of all our ads for other teams to build services and functionality on, and this recommender is an important first step to achieve that. . (This post was first published on tech.finn.no) . Resources .",
            "url": "https://simeneide.github.io/blog/nlp/2017/09/11/deep-nlp-rec.html",
            "relUrl": "/nlp/2017/09/11/deep-nlp-rec.html",
            "date": " ‚Ä¢ Sep 11, 2017"
        }
        
    
  
    
        ,"post8": {
            "title": "Jupyter lab - First impression",
            "content": "Every three months or so I get really annoyed about Jupyter Notebook being so limited, and I usually spend half a day browsing alternatives like Spyder, PyCharm and Rodeo. Usually my search phrase is ‚ÄúRstudio for python‚Äù, but wasting half a day or more I still end up with jupyter notebook. Although many good alternatives, the fact that you can work in the browser directly on the server makes it very simple to set up. . The last two weeks I have been testing out jupyter lab as a substitute for jupyter notebook for development work. Jupyter lab comes from the jupyter team, and is currently in their ‚ÄúVery early developer preview Alpha‚Äù, whatever that means. I have mainly used the notebook part of it, and that works more or less the same as jupyter notebook. Except for changing the locations of some buttons, jupyter lab does not (even in very early preview alpha) limit the use for a normal notebook user. . However, they have taken it much closer to an IDE by including tabs, window locations, a shell and a text editor. By doing that, it is actually possible to develop in a .py file and simultaneously run the code in a console. This is much closer to what my beloved Rstudio does for R, and is highly appreciated. . The main thing I feel is missing is all the keyboard shortcuts. . A Ctrl+Enter to execute a selected code block in the .py file onto the console is my main loss. | Also, I find myself reorganising the tabs all the time. Shortcuts to arrange the different tabs in different ways like ShiftIt would speed up development. | . Of course, I do not hold grudge against the team since they are only in its early preview developer alpha stage. I look forward to the time they move from ‚Äúvery early developer preview alpha‚Äù to just ‚Äúearly developer preview alpha‚Äù! .",
            "url": "https://simeneide.github.io/blog/jupyter/2017/07/30/jupyter-lab.html",
            "relUrl": "/jupyter/2017/07/30/jupyter-lab.html",
            "date": " ‚Ä¢ Jul 30, 2017"
        }
        
    
  
    
        ,"post9": {
            "title": "Collaborative Filtering Recommendations in Spreadsheets",
            "content": "Most people have a love-hate relationship to spreadsheets. The spreadsheet format is simple and intuitive, and doing calculations becomes really easy. However, they quickly become too complicated as well. . . Jeremy Howard‚Äôs lecture explaining embeddings was a great use of Excel, and I implemented my own version of his excel-sheet using it for illustration purposes on how recommendation algorithms work. . Recommendations are everywhere: Netflix is trying to propose the most relevant movies, and Google is serving you personalised ads that are hopefully a (little less) annoying. The gold standard algorithm is collaborative filtering. The idea of collaborative filtering is to be able to find relevant items to recommend a user given what the user looked at before. . The full excel sheet can be found here (it is view-only, so make a copy to try it out!). . You start off getting your dataset. In our case it consist of four users that have clicked or not clicked on four different items: . . The goal of a collaborative filtering model is to predict this data. That is, if we give the model the user ‚ÄúEspen‚Äù and the item ‚ÄúMacbook Pro‚Äù, it should be able to predict a number close to one. . The model is parameterised by giving each user and each item two random numbers each. We call these numbers for ‚Äúembeddings‚Äù: . . We say that our model predicts a click/no click on a pair of user and item by multiplying the embeddings. That is, we find the first embedding of Espen and multiplies it with the first embedding of the Macbook Pro. Then, we do the same for the second embedding. . -0.380.29 + -0.35-0.45 = 0.048 . That is pretty far from 1 (which is the number the model tries to predict). However, we have not trained the model yet, so it is pretty dumb so far. . The full excel sheet looks like this: . . We have seen column A to H already. Column I to L is just a copy of the embeddings from the users and items shown in the dataset. Column M is the prediction of the model (see that Espen has a 0.048 score for the Macbook Pro). Finally, column N tells us how far off we are at that particular prediction (0.952 for Espen‚Äôs case). . Since we want to make our predictions as close as the truth as possible (the truth is column H), we could say that we want as small errors as possible. That would be the same as saying we want the smallest Average Error possible (N13). The way we will get that is to alter these embeddings. If we can get those embeddings to be at certain values such that our average error is close to zero, we have made it! . One way to go forward is to change these numbers manually. If I change the sign of the first embedding of Espen to something positive I will get a higher prediction for the macbook pro. Also, if I change the sign of the second embedding of Kamilla I will also decrease the error. Now it looks like this: . . We have managed to decrease the average error from 0.71 to 0.64! Now, its pretty hard to do this by hand, so to help me I installed a little Add-on called ‚Äúsolver‚Äù in google spreadsheets. Basically what it does it to minimize cell N13 (which is where we have calculated our Average Error) by changing cells C3:D10 (that is where we have put all our embeddings (random numbers)). . . After pressing ‚ÄúSolve‚Äù the thing changes the embeddings and comes up with an error of 0.49! You can see it came up with better numbers so that our predictions (column M) are closer to the actual truth (column H). . . Doing this another time I actually get an average error of zero. Our model is perfectly predicting all the observations we have in the dataset, and we are done! . . The ‚Äúreal‚Äù collaborative filtering algorithms that operate in the wild is very similar to this one. They use more data and use more than two embeddings per user. At FINN.no, we are maybe using 200m datapoints and 100 ‚Äúembedding-numbers‚Äù to make a recommendation model. Getting an error of zero is of course not normal. Real people are complicated, contradictive and noisy. . We‚Äôre also not doing it in Excel, but spark and tensorflow. Have a look at the presentation I held for Oslo Data Science Meetup if you want to know more about that. .",
            "url": "https://simeneide.github.io/blog/matrix%20factorization/recsys/2017/05/28/CFexcel.html",
            "relUrl": "/matrix%20factorization/recsys/2017/05/28/CFexcel.html",
            "date": " ‚Ä¢ May 28, 2017"
        }
        
    
  
    
        ,"post10": {
            "title": "Presentation from Oslo Data Science Meetup",
            "content": "In February I talked about the recommendation models we have at FINN.no, and how we work to develop and test new models. It was exciting to be talking to so many people about technical stuff, but even more interesting to hear questions and comments you can take back to try out. . The full presentation can be downloaded here. . .",
            "url": "https://simeneide.github.io/blog/2017/03/30/osloDataSciencePresentation.html",
            "relUrl": "/2017/03/30/osloDataSciencePresentation.html",
            "date": " ‚Ä¢ Mar 30, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Biography . Mathematician with hacking skills at the Norwegian marketplace FINN.no and at the machine learning startup Arctic Datalab. Also doing a phd in statistics at University of Oslo. Working on personalization systems and other machine learning tasks using behaviour, image and text. Background from mathematics, statistics and financial modeling. . List your academic interests. . [interests] interests = [ ‚ÄúDeep Recommenders‚Äù, ‚ÄúDecision Making‚Äù, ‚ÄúBandits and RL‚Äù, ‚ÄúBayesian models‚Äù, ] +++ .",
          "url": "https://simeneide.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://simeneide.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}