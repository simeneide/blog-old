{
  
    
        "post0": {
            "title": "Bayesian Neural Nets and how to train them",
            "content": "General setup . We have a dataset $D = [ {x_i, y_i }, i=1,...,n]$, and have defined a likelihood function $P(D| theta)$ where $ theta in R^d$ are some parameters defined in the model. We have also already defined a prior for these parameters $P( theta)$. The posterior distribution can then be written as . $$ P( theta | D) = frac{P(D| theta) * P( theta)}{P(D)} propto P(D| theta) * P( theta) $$Finding $P(D)$ is impossible for all but the simplest cases, and as we are interested in complicated likelihood functions such as neural networks, it will clearly not work for us. Therefore, we only have the posterior distribution up to a constant. Luckily, there has been developed multiple techniques that can find an approximation to the posterior distribution that only requires There exist multiple techniques to infer the posterior distribution of a bayesian neural network: . Variational Inference | Dropout | SWAG | Markov Chain Monte Carlo | Stochastic Markov Chain Monte Carlo (SG-MCMC) | . Motivating example . Throughout the post we will use a motivating problem to show what we mean. Assume we have collected $N$ data points $(x_n, y_n), n le N$ where $x_n in R^2$ is a two dimensional vector, and $y_n in R^1$ is a one dimensional response. We generate the data using a very simple &quot;neural net&quot;: $$y_n = beta_0 + beta x_n + N(0, sigma)$$ . where $ beta_0$, $ beta$ and $ sigma$ are the parameters of the model. We will collect all three parameters in the parameter $ theta := { beta_0, beta, sigma }$ just to make it easier to write. . We can see that given both the input data $x_n$ and the parameters $ theta$ y_n is actually normally distributed. That is what we call the likelihood function: . $$ P(D| theta) = prod_{n=1}^N P(y_n | theta, x_n) = prod_{n=1}^N N( beta_0 + beta x_n , sigma)$$ . Let us generate a dataset with $ beta_0 = -1$, $ beta = 2.0$ and $ sigma = 0.1$: . N = 30 beta0 = torch.tensor([-1.0]) beta_true = torch.tensor([2.0]) sigma_true = torch.tensor([0.5]) X = dist.Uniform(-1,1).sample((N,)) Y = beta0 + X *beta_true + sigma_true*torch.normal(0,1, (N,)) data = {&#39;x&#39; : X,&#39;y&#39; : Y} ( alt.Chart(pd.DataFrame(data)).mark_circle(size=60) .encode( x=&#39;x&#39;, y=&#39;y&#39;) .properties(title=&quot;X versus Y in the real data&quot;) .interactive() ) . Now, the goal in supervised learning is to find an estimate of the parameters $ theta$. Our objective is to maximize the likelihood function plus a prior belief of what the parameters could be. In this example we&#39;ll make a really stupid belief and say that it is equally possible to find the parameters anywhere on the real line: $P( theta) sim 1$. This simplifies the analysis, and we can then write the posterior as proportional to the likelihood only: . $$ P( theta | X,Y) = prod_{n=1}^N N(y_n | beta_0 + beta x_n , sigma^2) $$We can implement this model in pytorch in the following way: . class BayesNet(nn.Module): def __init__(self, seed = 42): super().__init__() torch.random.manual_seed(seed) # Initialize the parameters with some random values self.beta0 = nn.Parameter(torch.randn((1,))) self.beta = nn.Parameter(torch.randn((1,))) self.sigma = nn.Parameter(torch.tensor([1.0]) ) # this has to be positive def forward(self, data: dict): return self.beta0 + self.beta*data[&#39;x&#39;] def loglik(self, data): # Evaluates the log of the likelihood given a set of X and Y yhat = self.forward(data) logprob = dist.Normal(yhat, self.sigma.abs()).log_prob(data[&#39;y&#39;]) return logprob.sum() def logpost(self, data): return self.loglik(data) . model = BayesNet(seed =2) model.loglik(data) . tensor(-79.2277, grad_fn=&lt;SumBackward0&gt;) . Markov Chain Monte Carlo (MCMC) . MCMC is the &quot;traditional&quot; way of finding the posterior distribution. It is an iterative algorithm (the markov chain name) that is updating the belief of what the model parameters $ theta$ should be. I.e. we end up with a loong chain of parameter values: $ theta_1, theta_2, ..., theta_{n}$. However, we are not looking for a fixed value, but a distribution. Luckily, there are theory that tells us that if you run this sequence for long enough, then all values $ theta_n$ will be samples from the posterior distribution. Voila! . So how does it work? . Metropolis MCMC algorithm . The metropolis MCMC algorithms does nothing but starting in some random position $ theta_0$ and randomly tries to go in a direction (e.g. add a Normal distribution $ theta_1 = theta_0 + N(0,1)$). If we improved (meaning that $P( theta | D)$ increased) we use that new value. If it didnt improve, we may still move to that point depending on some probability. . [ADD A DRAWING HERE THAT SHOWS ] . Formally the algorithm looks like this: . Initialize a starting point $ theta_0$. This can either be random or somewhere you think is reasonable. For instance, you can start in the center of your prior distribution $argmax_{ theta} P( theta)$. | For each $n=1,2,3,...$ do the following: . Sample a proposal $ theta_*$ using a proposal distribution: $ theta_* sim J( theta_* | theta_{n-1})$ (for example a multivariate Normal distribution: $J( theta_* | theta_{n-1}) = N( theta_* | theta_{n-1}, alpha I)$) | Compute &quot;how much better this proposal is than the previous: | $$ r = frac{P( theta_*|D)}{P( theta_{n-1}|D)} $$ . Set | | $$ theta_n = begin{cases} theta_* &amp; text{with probability} text{ min}(1,r) theta_{n-1} &amp; text{if not} end{cases} $$There is one technical constraint on this proposal distribution $J$ and that is that it should be symmetric. That means it should be just as likely to go in either direction: $J( theta_a | theta_b) = J( theta_b | theta_a)$. Our example above, a multivariate normal with the previous step as mean, satisfy this requirement. . So why should this thing work? First, see that if we get a better set of parameter then $P( theta_*|D) &gt; P( theta_{n-1}|D)$ and the ratio is above 1. Then we will always move to the new value (with probability 1)! That is comforting. If I stand somewhere on a smooth mountain and only take a step whenever that step is upwards I can be pretty certain I reach the top! . But what about that second term? What if we actually dont improve? Looking at the algorithm, that is the case when r is less than 1. We then have a positive possibility of moving anyways. Intuitively this is important for two reasons: . We want to find a posterior distribution at the end. If we only moved whenever we improved we would end up with a final value. Actually moving in slightly worse directions will allow our parameters to wiggle around the optimal solution a little bit. And luckily, this kind of wiggling will give us the posterior distribution! | Having a positive probability of moving in wrong directions also gives us a chance to avoid local minima. In fact, since our proposal distribution has a positive probability of jumping to any set of parameter values from any point, one can prove that the metropolis mcmc algorithm will find the optimum if it just runs for long enough. | Step size aka learning rate . Given that we choose a gaussian proposal distribution with mean of the previous parameter set, we still need to set the covariance matrix of the distribution. In the example above it was $ alpha I$, where $ alpha &gt; 0$ and $I$ is the identity matrix. Given this parameterization $ alpha$ determines how far we should try to jump in the metropolis algorithm. A large $ alpha$ will make us often jump far, whereas a small $ alpha$ will make us jump shortly. If we do short jumps we are likely to get proposal parameters that does not perform too bad and the metropolis algorithm will often accept the new parameters, but we will take very short steps each time. On the other hand, if we do large jumps we may sometiems get very good gains, but they will also be very bad very often. Therefore larger values of $ alpha$ will cause the accept probability to be low, but with large gains whenver it accepts. . This trade off looks very similar to learning rates in deep learning: Small steps will converge but slowly, and large steps takes giant leaps of faith and may not converge very well. The difference is of course that the metropolis algorithm will just not accept any proposals if you set $ alpha$ too high. There are more complicated algorithms that tries to auto-set $ alpha$, but for now we will just find a reasonable value (by trial and error) and stick to it. . Implementation of Metropolis algorithm . Let us implement a small &quot;optimizer&quot; that finds the posterior distribution using the metropolis algorithm. The main component of this class is the step() function, and it goes through the steps above. In addition we have implemented a fit() function for the training loop and a dictionary that holds all the parameters values over iterations so we can look at them later: . class MetropolisOptimizer(): def __init__(self, net, alpha): super().__init__() self.net = net self.alpha = alpha @torch.no_grad() def step(self, data=None): # Step 1: proposal_net = copy.deepcopy(self.net) for name, par in proposal_net.named_parameters(): newpar = par + torch.normal(torch.zeros_like(par), self.alpha) par.copy_(newpar) # Step 2: calculate ratio ratio = torch.exp(proposal_net.logpost(data) - self.net.logpost(data)) # Step 3: update with some probability: if (random.random()&lt;ratio).bool(): self.net = proposal_net else: pass return self.net def fit(self, data=None, num_steps=1000): # We create one tensor per parameter so that we can keep track of the parameter values over time: self.parameter_trace = {key : torch.zeros( (num_steps,) + par.size()) for key, par in self.net.named_parameters()} for s in range(num_steps): current_net = self.step(data) for key, val in current_net.named_parameters(): self.parameter_trace[key][s,] = val.data return True model = BayesNet() trainer = MetropolisOptimizer(model, alpha=0.02) # Train the model (and take the time): %time trainer.fit(data, num_steps=5000) . CPU times: user 2.32 s, sys: 22.7 ms, total: 2.34 s Wall time: 2.97 s . True . We only have 3 parameters and can visualize all of them. We see that all three variables first trods its way towards the area were its &quot;supposed to be&quot; and then starts wiggling around that area. This is the posterior distribution! . In addition, we visualize a two dimensional plot of where $ beta_0$ and $ beta$ are over all steps. We can see that they start in the lower right area and then quickly iterates itself towards where the posterior distributions should be in the upper left corner: . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-09T09:57:18.064574 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Variational Inference . Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) .",
            "url": "https://simeneide.github.io/blog/bayesian%20neural%20net/2020/11/06/bayesian-deep-learning.html",
            "relUrl": "/bayesian%20neural%20net/2020/11/06/bayesian-deep-learning.html",
            "date": " • Nov 6, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post updated",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . &quot;Why posterior distribution? I just want my neural net to be good&quot; . General setup . We have a dataset $D = [ {x_i, y_i }, i=1,...,n]$, and have defined a likelihood function $P(D| theta)$ where $ theta in R^d$ are some parameters defined in the model. We have also already defined a prior for these parameters $P( theta)$. The posterior distribution can then be written as . $$ P( theta | D) = frac{P(D| theta) * P( theta)}{P(D)} propto P(D| theta) * P( theta) $$Finding $P(D)$ is impossible for all but the simplest cases, and as we are interested in complicated likelihood functions such as neural networks, it will clearly not work for us. Therefore, we only have the posterior distribution up to a constant. Luckily, there has been developed multiple techniques that can find an approximation to the posterior distribution that only requires There exist multiple techniques to infer the posterior distribution of a bayesian neural network: . Variational Inference | Dropout | SWAG | Markov Chain Monte Carlo | Stochastic Markov Chain Monte Carlo (SG-MCMC) | . Markov Chain Monte Carlo (MCMC) . MCMC is the &quot;traditional&quot; way of finding the posterior distribution. It is an iterative algorithm (the markov chain name) that is updating the belief of what the model parameters $ theta$ should be. I.e. we end up with a loong chain of parameter values: $ theta_1, theta_2, ..., theta_{n}$. However, we are not looking for a fixed value, but a distribution. Luckily, there are theory that tells us that if you run this sequence for long enough, then all values $ theta_n$ will be samples from the posterior distribution. Voila! . So how does it work? . Metropolis MCMC algorithm . The metropolis MCMC algorithms does nothing but starting in some random position $ theta_0$ and randomly tries to go in a direction (e.g. add a Normal distribution $ theta_1 = theta_0 + N(0,1)$). If we improved (meaning that $P( theta | D)$ increased) we use that new value. If it didnt improve, we may still move to that point depending on some probability. . [ADD A DRAWING HERE THAT SHOWS ] . Formally the algorithm looks like this: . Initialize a starting point $ theta_0$. This can either be random or somewhere you think is reasonable. For instance, you can start in the center of your prior distribution $argmax_{ theta} P( theta)$. | For each $n=1,2,3,...$ do the following: . Sample a proposal $ theta_*$ using a proposal distribution: $ theta_* sim J( theta_* | theta_{n-1})$ (for example a multivariate Normal distribution: $J( theta_* | theta_{n-1}) = N( theta_* | theta_{n-1}, I)$ | Compute &quot;how much better this proposal is than the previous: | $$ r = frac{P( theta_*|D)}{P( theta_{n-1}|D)} $$ . Set | $$ theta_n = begin{cases} . theta_* &amp; text{with probability} text{ min}(1,r) theta_{n-1} &amp; text{if not} end{cases} . $$ . | There is one technical constraint on this proposal distribution $J$ and that is that it should be symmetric. That means it should be just as likely to go in either direction: $J( theta_a | theta_b) = J( theta_b | theta_a)$. Our example above, a multivariate normal with the previous step as mean, satisfy this requirement. . So why should this thing work? First, see that if we get a better set of parameter then $P( theta_*|D) &gt; P( theta_{n-1}|D)$ and the ratio is above 1. Then we will always move to the new value (with probability 1)! That is comforting. If I stand somewhere on a smooth mountain and only take a step whenever that step is upwards I can be pretty certain I reach the top! . But what about that second term? What if we actually dont improve? Looking at the algorithm, that is the case when r is less than 1. . Learning rate . Variational Inference . Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://simeneide.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://simeneide.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Biography . Mathematician with hacking skills at the Norwegian marketplace FINN.no and at the machine learning startup Arctic Datalab. Also doing a phd in statistics at University of Oslo. Working on personalization systems and other machine learning tasks using behaviour, image and text. Background from mathematics, statistics and financial modeling. . List your academic interests. . [interests] interests = [ “Deep Recommenders”, “Decision Making”, “Bandits and RL”, “Bayesian models”, ] +++ .",
          "url": "https://simeneide.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://simeneide.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}