<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Takeaways Recsys 2018 | Simen Eide</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Takeaways Recsys 2018" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="For the first time Ive actually made a summary of all the papers and presentations I found noteworthy at a conference (allright, there were more, but this is a start). Below is my notes, with links etc. The purpose of the notes is mainly for myself to remember and revisit what I found interesting, but I see no reasons not to share to others. Does not include my own paper." />
<meta property="og:description" content="For the first time Ive actually made a summary of all the papers and presentations I found noteworthy at a conference (allright, there were more, but this is a start). Below is my notes, with links etc. The purpose of the notes is mainly for myself to remember and revisit what I found interesting, but I see no reasons not to share to others. Does not include my own paper." />
<link rel="canonical" href="https://simeneide.github.io/blog/recsys/conference/2018/10/06/recsys2018.html" />
<meta property="og:url" content="https://simeneide.github.io/blog/recsys/conference/2018/10/06/recsys2018.html" />
<meta property="og:site_name" content="Simen Eide" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-06T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://simeneide.github.io/blog/recsys/conference/2018/10/06/recsys2018.html","@type":"BlogPosting","headline":"Takeaways Recsys 2018","dateModified":"2018-10-06T00:00:00-05:00","datePublished":"2018-10-06T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://simeneide.github.io/blog/recsys/conference/2018/10/06/recsys2018.html"},"description":"For the first time Ive actually made a summary of all the papers and presentations I found noteworthy at a conference (allright, there were more, but this is a start). Below is my notes, with links etc. The purpose of the notes is mainly for myself to remember and revisit what I found interesting, but I see no reasons not to share to others. Does not include my own paper.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://simeneide.github.io/blog/feed.xml" title="Simen Eide" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Simen Eide</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Takeaways Recsys 2018</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2018-10-06T00:00:00-05:00" itemprop="datePublished">
        Oct 6, 2018
      </time>
       ‚Ä¢ <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#recsys">recsys</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#conference">conference</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h3"><a href="#keynote-dlrs---joachims-deep-learning-with-logged-bandit-feedback">Keynote dlrs - Joachims: Deep learning with logged bandit feedback</a></li>
<li class="toc-entry toc-h3"><a href="#youtube-minmin-chen-off-policy-correction-for-a-reinforce-rec-system">Youtube, Minmin Chen: Off-policy correction for a REINFORCE Rec system</a>
<ul>
<li class="toc-entry toc-h4"><a href="#results">Results</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#recsys-competition-winners-two-stage-model-for-automatic-playlist-continuation-at-scale">Recsys-competition winners: Two-stage model for Automatic Playlist Continuation at Scale</a></li>
<li class="toc-entry toc-h3"><a href="#categorical-attributes-based-item-classification-for-recommender-systems-hiarchical-softmax-and-multi-loss">Categorical-attributes-based item classification for recommender systems: hiarchical softmax and multi loss</a></li>
<li class="toc-entry toc-h3"><a href="#keynote-2-dlrs---ray-jiang-deepmind-slate-recommendation-part-1">Keynote 2 dlrs - Ray Jiang, deepmind: slate recommendation (part 1)</a></li>
<li class="toc-entry toc-h3"><a href="#calibrated-recommendations">Calibrated Recommendations</a></li>
<li class="toc-entry toc-h3"><a href="#explore-exploit-and-explain-personalizing-explainable-recommendations-with-bandits">Explore, Exploit, and Explain: Personalizing Explainable Recommendations with Bandits</a></li>
<li class="toc-entry toc-h3"><a href="#invited-talk-netflix-correlation--causation">Invited talk Netflix: Correlation &amp; Causation</a></li>
<li class="toc-entry toc-h3"><a href="#generation-meets-recommendation---generating-new-items-that-fit-most-users">Generation meets recommendation - ‚ÄúGenerating new items that fit most users‚Äù</a></li>
<li class="toc-entry toc-h3"><a href="#on-the-robustness-and-discriminative-power-of-information-retrieval-metrics-for-top-n-recommendation">On the robustness and discriminative power of information retrieval metrics for top-N recommendation</a></li>
<li class="toc-entry toc-h3"><a href="#unbiased-offline-recommender-evaluation-for-missing-not-at-random-implicit-feedback">Unbiased offline recommender evaluation for missing-not-at-random implicit feedback</a></li>
<li class="toc-entry toc-h3"><a href="#recogym">RecoGym</a></li>
<li class="toc-entry toc-h3"><a href="#news-session-based-recommendations-using-dnn">News session-based recommendations using DNN</a></li>
<li class="toc-entry toc-h3"><a href="#what-happens-if-users-only-share-last-n-days-of-data-exploring-recommendations-under-user-controlled-data-filtering">What happens if users only share last n days of data? (Exploring recommendations under user-controlled data filtering)</a></li>
<li class="toc-entry toc-h3"><a href="#interactive-recommendation-via-deep-neural-memory-augmented-contextual-bandits">Interactive recommendation via deep neural memory augmented contextual bandits</a></li>
</ul><p>For the first time Ive actually made a summary of all the papers and presentations I found noteworthy at a conference (allright, there were more, but this is a start).
Below is my notes, with links etc.
The purpose of the notes is mainly for myself to remember and revisit what I found interesting, but I see no reasons not to share to others.
Does not include my own <a href="">paper</a>.</p>

<h3 id="keynote-dlrs---joachims-deep-learning-with-logged-bandit-feedback">
<a class="anchor" href="#keynote-dlrs---joachims-deep-learning-with-logged-bandit-feedback" aria-hidden="true"><span class="octicon octicon-link"></span></a>Keynote dlrs - Joachims: Deep learning with logged bandit feedback</h3>

<ul>
  <li>Paper: http://www.cs.cornell.edu/people/tj/publications/joachims_etal_18a.pdf</li>
  <li>idea: utilize current policy to build a better contextual bandits to recommend.</li>
  <li>using Inverse Propensity Scoring</li>
  <li>Using Self-normalizing IPS estimator (SNIPS)</li>
  <li>Also using self normalizing</li>
</ul>

<p><img alt="2018-10-06-recsys2018-0867f3e3.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-0867f3e3.png" width="" height=""></p>

<p><img alt="2018-10-06-recsys2018-7462e07d.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-7462e07d.png" width="" height=""></p>

<p><img alt="2018-10-06-recsys2018-2df58514.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-2df58514.png" width="" height=""></p>

<p>A very similar talk seem to be posted here:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/lzA5K4im2no" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>

<h3 id="youtube-minmin-chen-off-policy-correction-for-a-reinforce-rec-system">
<a class="anchor" href="#youtube-minmin-chen-off-policy-correction-for-a-reinforce-rec-system" aria-hidden="true"><span class="octicon octicon-link"></span></a>Youtube, Minmin Chen: Off-policy correction for a REINFORCE Rec system</h3>

<ul>
  <li>Invited talk on the evaluation workshop REVEAL</li>
  <li>Youtube shared their work on how the models they used now works, focus on evaluation</li>
  <li>Maximized recommendations based on expected future reward</li>
  <li>they do not use td to train the model, rather the all the actual future rewards and discounts them to get training signal.</li>
</ul>

<p><img alt="2018-10-06-recsys2018-ae6ed169.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-ae6ed169.png" width="" height=""></p>

<p><img alt="2018-10-06-recsys2018-343021fe.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-343021fe.png" width="" height=""></p>

<ul>
  <li>
    <p>Corrects off-policy updates with importance sampling/IPS
<img alt="2018-10-06-recsys2018-dd53f244.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-dd53f244.png" width="" height=""></p>
  </li>
  <li>Exploration is costly, so they tune ut with an extra weight that they set.</li>
  <li>Recommends a set of top K items. Assume additive rewards:
<img alt="2018-10-06-recsys2018-954be358.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-954be358.png" width="" height="">
</li>
</ul>

<p><img alt="2018-10-06-recsys2018-03485057.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-03485057.png" width="" height=""></p>

<h4 id="results">
<a class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h4>
<ul>
  <li>Improved recs, also able to recommend more items into the tail.</li>
</ul>

<p><img alt="2018-10-06-recsys2018-b4d59684.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-b4d59684.png" width="" height=""></p>

<h3 id="recsys-competition-winners-two-stage-model-for-automatic-playlist-continuation-at-scale">
<a class="anchor" href="#recsys-competition-winners-two-stage-model-for-automatic-playlist-continuation-at-scale" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recsys-competition winners: Two-stage model for Automatic Playlist Continuation at Scale</h3>

<ul>
  <li>Challenge website: http://www.recsyschallenge.com/2018/</li>
  <li>Winner paper: http://www.cs.toronto.edu/~mvolkovs/recsys2018_challenge.pdf</li>
  <li>Task was to complete a user playlist at spotify.</li>
  <li>A playlist may have be created over a long time.</li>
  <li>Given the first items, predict the last ones.</li>
</ul>

<p>Approach:</p>

<ul>
  <li>step 1: Reduce candidate set of all items to 20k by using a temporal convolutional layer.
    <ul>
      <li>(lstm worked too, but was slower to train and iterate on).</li>
      <li>The step 1 was really about maximizing recall.</li>
    </ul>
  </li>
  <li>Step 2: xgboost classifier on these candidates</li>
</ul>

<p><img alt="2018-10-06-recsys2018-7267c259.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-7267c259.png" width="" height=""></p>

<h3 id="categorical-attributes-based-item-classification-for-recommender-systems-hiarchical-softmax-and-multi-loss">
<a class="anchor" href="#categorical-attributes-based-item-classification-for-recommender-systems-hiarchical-softmax-and-multi-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Categorical-attributes-based item classification for recommender systems: hiarchical softmax and multi loss</h3>

<ul>
  <li>Paper: https://dl.acm.org/citation.cfm?id=3240367</li>
  <li>Setting: Next item prediction with items within some category structure.</li>
  <li>
    <p>Using negative sampling during training</p>
  </li>
  <li>
    <p>Does the recommender improve by predicting a hiarchical softmax instead of doing multi target prediction?</p>
  </li>
  <li>Result: Using hiarchical modeling is better than multi target. Testet with MAP@5 on recsys16 dataset and ‚Äúlarge propertary dataset‚Äù.</li>
  <li>Also helps with cold start</li>
</ul>

<p>Own comments: Unsure of the improvement is due to negative sampling or that you infer more structure in your data/model.</p>

<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">"Categorical-Attributes-Based Item Classification for Recommender Systems" by <a href="https://twitter.com/QianZhao3?ref_src=twsrc%5Etfw">@QianZhao3</a> and Google folks lead by <a href="https://twitter.com/edchi?ref_src=twsrc%5Etfw">@edchi</a> - really interesting idea: categorical labels as *outputs* of multitask model you are optimizing when recommending items <a href="https://twitter.com/hashtag/RecSys2018?src=hash&amp;ref_src=twsrc%5Etfw">#RecSys2018</a> <a href="https://t.co/Bkljw0zVFf">https://t.co/Bkljw0zVFf</a> <a href="https://t.co/PavBxdtLaX">pic.twitter.com/PavBxdtLaX</a></p>‚Äî Xavier @ #recsys2018üéóü§ñüèÉ (@xamat) <a href="https://twitter.com/xamat/status/1048331032619970560?ref_src=twsrc%5Etfw">October 5, 2018</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p><img alt="2018-10-06-recsys2018-0566e34a.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-0566e34a.png" width="50%" height=""></p>

<p><img alt="2018-10-06-recsys2018-0224ef5e.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-0224ef5e.png" width="50%" height=""></p>

<h3 id="keynote-2-dlrs---ray-jiang-deepmind-slate-recommendation-part-1">
<a class="anchor" href="#keynote-2-dlrs---ray-jiang-deepmind-slate-recommendation-part-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Keynote 2 dlrs - Ray Jiang, deepmind: slate recommendation (part 1)</h3>

<ul>
  <li>Relevant paper (seems unpublished): https://arxiv.org/pdf/1803.01682.pdf</li>
  <li>predict a full feed instead of single items</li>
  <li>use a VAE to do this,</li>
  <li>‚ÄúWorks really well‚Äù.</li>
  <li>Tested on Recsys 2015: was the best slate dataset they could find</li>
</ul>

<p><img alt="2018-10-06-recsys2018-ce298161.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-ce298161.png" width="" height=""></p>

<p><img alt="2018-10-06-recsys2018-da23e997.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-da23e997.png" width="" height=""></p>

<p>https://arxiv.org/abs/1803.01682</p>

<h3 id="calibrated-recommendations">
<a class="anchor" href="#calibrated-recommendations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Calibrated Recommendations</h3>

<ul>
  <li>Paper: https://dl.acm.org/citation.cfm?id=3240372</li>
  <li>If you have seen 70% drama and 30% horror, optimizing a recommender on precision, the best solution is to give you 100% drama and get 70% precision.</li>
  <li>The paper suggests to calibrate the recommendations to be more representative.</li>
  <li>Done by regularizing the recommendations with the KL divergence of categories (genres in this case)</li>
  <li>Done as a post processing step.</li>
  <li>Result: Can rerank top recommendations to a much more representative distribution without losing accuracy.</li>
</ul>

<p>https://dl.acm.org/citation.cfm?id=3240372</p>

<h3 id="explore-exploit-and-explain-personalizing-explainable-recommendations-with-bandits">
<a class="anchor" href="#explore-exploit-and-explain-personalizing-explainable-recommendations-with-bandits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Explore, Exploit, and Explain: Personalizing Explainable Recommendations with Bandits</h3>

<ul>
  <li>Paper: https://dl.acm.org/citation.cfm?id=3240354</li>
  <li>Feed-bandit that uses a factorization machine to predict and explain recommendations</li>
  <li>context: Home page of spotify account. Different shelves of recommendations, each with an explanation (‚Äúbecause you recently listened to..‚Äù)</li>
</ul>

<h3 id="invited-talk-netflix-correlation--causation">
<a class="anchor" href="#invited-talk-netflix-correlation--causation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Invited talk Netflix: Correlation &amp; Causation</h3>
<ul>
  <li>Yves Raimond, AI director Netflix</li>
  <li>Netflix‚Äôs approach: personalize everything</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Made some thoughts about the do operator P(Y</td>
          <td>do(X))</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Maybe better for recs to focus on P(click</td>
          <td>do(X)) - P(click</td>
          <td>not do X)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>IPS:</li>
  <li>pro: simple, model-agnostic</li>
  <li>con: only unbiased if no unobserved cofounders, high variance</li>
  <li>Alternative til IPS: Instrumental Variable</li>
  <li>used in econometrics</li>
  <li>pro: robust to unobserved cofounders</li>
  <li>con: bias/var depends on strength of IV, hard to scale</li>
</ul>

<p><img alt="2018-10-06-recsys2018-211b351e.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-211b351e.png" width="" height="">
<img alt="2018-10-06-recsys2018-7ab75917.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-7ab75917.png" width="" height=""></p>

<p><img alt="2018-10-06-recsys2018-4d1e1674.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-4d1e1674.png" width="" height=""></p>

<h3 id="generation-meets-recommendation---generating-new-items-that-fit-most-users">
<a class="anchor" href="#generation-meets-recommendation---generating-new-items-that-fit-most-users" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generation meets recommendation - ‚ÄúGenerating new items that fit most users‚Äù</h3>
<ul>
  <li>Paper: https://arxiv.org/abs/1808.01199</li>
</ul>

<blockquote>
  <ul>
    <li>‚ÄúConsider a movie studio aiming to produce a set of new movies for summer release: What types of movies it should produce? Who would the movies appeal to?‚Äù</li>
    <li>‚ÄúSpecifically, we leverage the latent space obtained by training a deep generative model‚Äîthe Variational Autoencoder (VAE)‚Äîvia a loss function that incorporates both rating performance and item reconstruction terms.‚Äù</li>
    <li>‚ÄúWe then apply a greedy search algorithm that utilizes this learned latent space to jointly obtain K plausible new items, and user groups that would find the items appealing.‚Äù</li>
  </ul>
</blockquote>

<h3 id="on-the-robustness-and-discriminative-power-of-information-retrieval-metrics-for-top-n-recommendation">
<a class="anchor" href="#on-the-robustness-and-discriminative-power-of-information-retrieval-metrics-for-top-n-recommendation" aria-hidden="true"><span class="octicon octicon-link"></span></a>On the robustness and discriminative power of information retrieval metrics for top-N recommendation</h3>
<ul>
  <li>Paper: https://dl.acm.org/authorize.cfm?key=N668684</li>
  <li>
    <p>An evaluation of robustness of many offline metrics at different ranking level. E.g. MRR@5, Recall@10, MAP@100, ‚Ä¶</p>
  </li>
  <li>Takeaway 1: Use a high cutoff (e.g. 100 instead of 10) when doing offline evaluations, like MRR. The metric is more robust, and highly correlated to the MRR@10 values</li>
  <li>Takeaway 2: MRR is one of the lesser robust offline metrics.</li>
</ul>

<p><img alt="2018-10-06-recsys2018-6ac93198.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-6ac93198.png" width="" height=""></p>

<p>Takeaway 2: mrr er ganske lite robust.</p>

<h3 id="unbiased-offline-recommender-evaluation-for-missing-not-at-random-implicit-feedback">
<a class="anchor" href="#unbiased-offline-recommender-evaluation-for-missing-not-at-random-implicit-feedback" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unbiased offline recommender evaluation for missing-not-at-random implicit feedback</h3>

<blockquote>
  <p>Implicit-feedback Recommenders (ImplicitRec) leverage positive only user-item interactions, such as clicks, to learn personalized user preferences. Recommenders are often evaluated and compared offline using datasets collected from online platforms. These platforms are subject to popularity bias (i.e., popular items are more likely to be presented and interacted with), and therefore logged ground truth data are Missing-Not-At-Random (MNAR).</p>
</blockquote>

<ul>
  <li>‚ÄúAverage over all‚Äù estimators are biased in Implicit rec datasets</li>
  <li>Use IPS to evaluate policies.</li>
  <li>reduce bias with 30% in a yahoo! music datset.</li>
  <li>Paper: https://dl.acm.org/citation.cfm?id=3240355</li>
</ul>

<h3 id="recogym">
<a class="anchor" href="#recogym" aria-hidden="true"><span class="octicon octicon-link"></span></a>RecoGym</h3>

<ul>
  <li>Simulation environment where you can evaluate your recommender agent</li>
  <li>Follows the same style as openAI gym: env.step(action)</li>
  <li>When we tried it a bit the day before, the users seemed to click on the same items over and over again, probably some tuning that needs to be done there?</li>
  <li>
    <p>This is sort of an alternative approach to offline evaluation. Simulators are limited by their generating model, but can we still use it to test algorithms for convergence etc?</p>
  </li>
  <li>Unrelated to talk and recogym, but some notes me and Olav did on rec simulations during conf. Same ideas:</li>
</ul>

<p><img alt="2018-10-06-recsys2018-d17df3a5.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-d17df3a5.png" width="" height=""></p>

<h3 id="news-session-based-recommendations-using-dnn">
<a class="anchor" href="#news-session-based-recommendations-using-dnn" aria-hidden="true"><span class="octicon octicon-link"></span></a>News session-based recommendations using DNN</h3>

<ul>
  <li>A recommendation algorithm to recommend news.</li>
  <li>Freshness and coldstart big problems.</li>
  <li>Separate item representation that uses a lot of content, independent of users</li>
  <li>Unfortunately not tested in prod (authors from large news corp.)</li>
  <li>Tested on offline data: Beats everything, incl gru4rec ++</li>
  <li>Paper: https://arxiv.org/abs/1808.00720</li>
  <li>Code: https://github.com/criteo-research/reco-gym</li>
</ul>

<p><img alt="2018-10-06-recsys2018-ba51b891.png" src="/blog/assets_old/assets/2018-10-06-recsys2018-ba51b891.png" width="" height=""></p>

<h3 id="what-happens-if-users-only-share-last-n-days-of-data-exploring-recommendations-under-user-controlled-data-filtering">
<a class="anchor" href="#what-happens-if-users-only-share-last-n-days-of-data-exploring-recommendations-under-user-controlled-data-filtering" aria-hidden="true"><span class="octicon octicon-link"></span></a>What happens if users only share last n days of data? (Exploring recommendations under user-controlled data filtering)</h3>

<blockquote>
  <ul>
    <li>‚ÄúUsing the MovieLens dataset as a testbed, we evaluated three widely used collaborative filtering algorithms.‚Äù</li>
    <li>‚ÄúOur experiments demonstrate that filtering out historical user data does not significantly affect the overall recommendation performance.‚Äù</li>
    <li>Impacts those who opted out (naturally)</li>
  </ul>
</blockquote>

<p>Paper: https://scholar.google.com/citations?user=Vyj2jeoAAAAJ&amp;hl=en#d=gs_md_cita-d&amp;p=&amp;u=%2Fcitations%3Fview_op%3Dview_citation%26hl%3Den%26user%3DVyj2jeoAAAAJ%26citation_for_view%3DVyj2jeoAAAAJ%3A2osOgNQ5qMEC%26tzom%3D420</p>

<h3 id="interactive-recommendation-via-deep-neural-memory-augmented-contextual-bandits">
<a class="anchor" href="#interactive-recommendation-via-deep-neural-memory-augmented-contextual-bandits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interactive recommendation via deep neural memory augmented contextual bandits</h3>

<ul>
  <li>created a recsys simulator? check out‚Ä¶</li>
  <li>Paper: https://dl.acm.org/citation.cfm?id=3240344</li>
</ul>

  </div><a class="u-url" href="/blog/recsys/conference/2018/10/06/recsys2018.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Notes, posts and publications</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/simeneide" title="simeneide"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/simeneide" title="simeneide"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
